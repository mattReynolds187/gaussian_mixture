This is a fully vectorized from scratch implimentation of a Gaussian Mixture Model for matrix completion. This project is inspired by a project I completed for MIT's edx course 'Machine Learning With Python: From Linear Models to Deep Learning'  

No external libraries besides numpy (and matplotlib for plotting) are used.  

TODO:  
The example_usage.ipynb file is currently without much explanation. Soon an updated version giving an explanation of the EM algorithm as well as more detailed explanations of how to use the model will be made available. 

The gaussian mixture constructor takes 3 arguments:  
X - nxd np.ndarray where n is the number of data points and d is the dimension of the data  
    the model expects 0 to represent non-existent entries  
K - number of Gaussian clusters used by the model  
seed - a seed for random initialization of parameters of the model  

To train the model call the run method. Run takes one optional argument:  
min_variance - float representing the smallest possible variance the model can obtain. This is to prevent vanishing variance problem. Future updates to this model may employ regularization to fix this issue.  

To plot the log likelihood use the plot_history method.  

Once the model has been run, use the fill_matrix method which takes the matrix to be filled as an argument.

Use the static method evaluate_rmse to evaluate the root mean square error of the model. This takes two arguments:  
-filled matrix generated by the model  
-test matrix to be compared with the filled matrix  

An example usage on preprocessed real netflix data (provided by MIT) is shown in the associated jupyter notebook. Each row in the file represents a netflix user and the ratings from 1-5 they gave to each movie (represented by the columns). Entries of 0 represent movies they have not reviewed.  

Future updates to this repository may include examples of how to preprocess the original messy netflix data from which this is derived.   
